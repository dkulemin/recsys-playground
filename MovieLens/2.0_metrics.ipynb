{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List\n",
    "import sys\n",
    "import importlib\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "REPO_RELATIVE_PATH = '..'\n",
    "\n",
    "if REPO_RELATIVE_PATH not in sys.path:\n",
    "    sys.path.append(REPO_RELATIVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = pd.read_csv(\n",
    "    f'{REPO_RELATIVE_PATH}/datasets/ml-1m/ml-1m.item',\n",
    "    sep='\\t',\n",
    "    header=0,\n",
    "    names=['item_id', 'movie_title', 'release_year', 'genre']\n",
    ")\n",
    "datasets = {\n",
    "    'random': pd.read_csv('splits/random/val.csv', sep='\\t', header=0),\n",
    "    'by_user': pd.read_csv('splits/by_user/val.csv', sep='\\t', header=0),\n",
    "    'lol': pd.read_csv('splits/leave_one_last/val.csv', sep='\\t', header=0),\n",
    "    't_user': pd.read_csv('splits/temporal_user/val.csv', sep='\\t', header=0),\n",
    "    't_global': pd.read_csv('splits/temporal_global/val.csv', sep='\\t', header=0),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Составим выборку случайных фильмов для тестирования метрик на разных сплитах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1365\n",
       "1    2706\n",
       "2    3667\n",
       "3    3684\n",
       "4    1881\n",
       "Name: item_id, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_recommendations = items.sample(frac=1, random_state=42).reset_index()['item_id']\n",
    "random_recommendations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_labels(\n",
    "    df: pd.DataFrame,\n",
    "    threshhold: int | float,\n",
    "    user_id_col: str = 'user_id',\n",
    "    item_id_col: str = 'item_id',\n",
    "    rating_col: str = 'rating'\n",
    ") -> pd.DataFrame:\n",
    "    return (\n",
    "        df\n",
    "        .sort_values([user_id_col, rating_col], ascending=[True, False])\n",
    "        .groupby(user_id_col)\n",
    "        .agg(\n",
    "            items=(item_id_col, lambda x: list(x)),\n",
    "            ratings=(rating_col, lambda x: list(x))\n",
    "        )\n",
    "        .apply(lambda x: [i for (i, r) in zip(x['items'], x['ratings']) if r > threshhold], axis=1)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id\n",
       "1                       [1035, 3105, 1193, 1836, 2018]\n",
       "2           [1945, 2002, 1357, 1957, 3468, 3451, 3068]\n",
       "3                             [1259, 1196, 1049, 1394]\n",
       "4                                                   []\n",
       "5    [2427, 3083, 2997, 1175, 2289, 348, 1392, 506,...\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_labels = prepare_labels(datasets['random'], 3)\n",
    "random_labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитаем метрики для разных сплитов на рандомной подборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_at_k_metrics(datasets: Dict[str, pd.DataFrame], metric_list: List[str], k: int, prepare_labels_kwargs: Dict = dict()) -> None:\n",
    "    metrics_module = importlib.import_module('src.metrics.metrics')\n",
    "    metrics_module = importlib.reload(metrics_module)\n",
    "    for df_name, df in datasets.items():\n",
    "        df_labels = prepare_labels(df, **prepare_labels_kwargs)\n",
    "        for metric_name in metric_list:\n",
    "            metric = getattr(metrics_module, metric_name)\n",
    "            result = df_labels.apply(lambda x: metric(random_recommendations, x, k)).mean()\n",
    "            print(f'{df_name} - {metric_name}: {result}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random - precision_at_k: 0.002046636470390874\n",
      "random - recall_at_k: 0.002795959045627951\n",
      "by_user - precision_at_k: 0.019867549668874177\n",
      "by_user - recall_at_k: 0.003730259055027287\n",
      "lol - precision_at_k: 0.00029308323563892143\n",
      "lol - recall_at_k: 0.0029308323563892145\n",
      "t_user - precision_at_k: 0.001583476764199656\n",
      "t_user - recall_at_k: 0.0019312661802910493\n",
      "t_global - precision_at_k: 0.010493827160493827\n",
      "t_global - recall_at_k: 0.0025974681336977377\n"
     ]
    }
   ],
   "source": [
    "compute_at_k_metrics(datasets, ['precision_at_k', 'recall_at_k'], 10, {'threshhold': 3})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оказывается случайная подборка лучше всего сработала для холодного старта, когда мы еще ничего не знаем о пользователе. С другой стороны в этом датасете просто самые длинные списки фильмов, так как брали всю историю просмотров."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
